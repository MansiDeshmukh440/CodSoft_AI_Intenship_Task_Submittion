{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yBXxDrhUW-OX",
        "outputId": "32a68a8b-cf1b-4519-d806-91a95ea2f711"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.8.0.76)\n",
            "Requirement already satisfied: facenet-pytorch in /usr/local/lib/python3.10/dist-packages (2.6.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.25.2)\n",
            "Requirement already satisfied: Pillow<10.3.0,>=10.2.0 in /usr/local/lib/python3.10/dist-packages (from facenet-pytorch) (10.2.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from facenet-pytorch) (2.31.0)\n",
            "Requirement already satisfied: torch<2.3.0,>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from facenet-pytorch) (2.2.2)\n",
            "Requirement already satisfied: torchvision<0.18.0,>=0.17.0 in /usr/local/lib/python3.10/dist-packages (from facenet-pytorch) (0.17.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from facenet-pytorch) (4.66.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->facenet-pytorch) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->facenet-pytorch) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->facenet-pytorch) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->facenet-pytorch) (2024.7.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (1.13.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch<2.3.0,>=2.2.0->facenet-pytorch) (12.5.82)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch<2.3.0,>=2.2.0->facenet-pytorch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch<2.3.0,>=2.2.0->facenet-pytorch) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "pip install opencv-python facenet-pytorch numpy\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import torch\n",
        "import numpy as np\n",
        "from facenet_pytorch import MTCNN, InceptionResnetV1\n",
        "from PIL import Image\n",
        "\n",
        "# Load MTCNN for face detection and InceptionResnetV1 for face recognition\n",
        "mtcnn = MTCNN(keep_all=True)\n",
        "model = InceptionResnetV1(pretrained='vggface2').eval()\n",
        "\n",
        "# Function to extract face embeddings\n",
        "def extract_face_embeddings(image):\n",
        "    img_cropped = mtcnn(image)\n",
        "    if img_cropped is not None:\n",
        "        img_embedding = model(img_cropped.unsqueeze(0))\n",
        "        return img_embedding\n",
        "    return None\n",
        "\n",
        "# Function to recognize faces\n",
        "def recognize_face(image, known_faces, known_names, threshold=0.6):\n",
        "    img_embedding = extract_face_embeddings(image)\n",
        "    if img_embedding is None:\n",
        "        return \"No face detected.\"\n",
        "\n",
        "    min_dist = float('inf')\n",
        "    recognized_name = \"Unknown\"\n",
        "\n",
        "    for i, known_embedding in enumerate(known_faces):\n",
        "        dist = torch.dist(img_embedding, known_embedding)\n",
        "        if dist < min_dist:\n",
        "            min_dist = dist\n",
        "            recognized_name = known_names[i]\n",
        "\n",
        "    if min_dist > threshold:\n",
        "        recognized_name = \"Unknown\"\n",
        "\n",
        "    return recognized_name\n",
        "\n",
        "# Load known faces and their names\n",
        "def load_known_faces(known_faces_dir):\n",
        "    known_faces = []\n",
        "    known_names = []\n",
        "    for filename in os.listdir(known_faces_dir):\n",
        "        if filename.endswith('.jpg') or filename.endswith('.png'):\n",
        "            name = os.path.splitext(filename)[0]\n",
        "            image = Image.open(os.path.join(known_faces_dir, filename))\n",
        "            known_faces.append(extract_face_embeddings(image))\n",
        "            known_names.append(name)\n",
        "    return known_faces, known_names\n",
        "\n",
        "# Update this path to your known faces directory\n",
        "known_faces_dir = '/known_faces.zip'  # Example: 'known_faces'\n",
        "known_faces, known_names = load_known_faces(known_faces_dir)\n",
        "\n",
        "# Real-time face detection and recognition\n",
        "cap = cv2.VideoCapture(0)  # Use 0 for webcam or provide the path to a video file\n",
        "\n",
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # Convert the frame to PIL format\n",
        "    frame_pil = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
        "\n",
        "    # Detect faces\n",
        "    boxes, _ = mtcnn.detect(frame_pil)\n",
        "\n",
        "    if boxes is not None:\n",
        "        for box in boxes:\n",
        "            x1, y1, x2, y2 = [int(b) for b in box]\n",
        "            face_img = frame_pil.crop((x1, y1, x2, y2))\n",
        "            name = recognize_face(face_img, known_faces, known_names)\n",
        "\n",
        "            # Draw rectangle around the face\n",
        "            cv2.rectangle(frame, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
        "            # Put name label\n",
        "            cv2.putText(frame, name, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 0, 0), 2)\n",
        "\n",
        "    # Display the resulting frame\n",
        "    cv2.imshow('Face Detection and Recognition', frame)\n",
        "\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "# When everything is done, release the capture\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "kxAmWORaC2yV",
        "outputId": "b094c410-2664-4db4-da9a-52f0ae04677e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NotADirectoryError",
          "evalue": "[Errno 20] Not a directory: '/known_faces.zip'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotADirectoryError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-92f9b75b7cba>\u001b[0m in \u001b[0;36m<cell line: 54>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;31m# Update this path to your known faces directory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0mknown_faces_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/known_faces.zip'\u001b[0m  \u001b[0;31m# Example: 'known_faces'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m \u001b[0mknown_faces\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mknown_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_known_faces\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mknown_faces_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;31m# Real-time face detection and recognition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-92f9b75b7cba>\u001b[0m in \u001b[0;36mload_known_faces\u001b[0;34m(known_faces_dir)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0mknown_faces\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0mknown_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mknown_faces_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.jpg'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotADirectoryError\u001b[0m: [Errno 20] Not a directory: '/known_faces.zip'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yDDy3dQbE_Iu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}